{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom pandas import read_csv\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score\nfrom xgboost import plot_importance\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error , make_scorer\nfrom math import sqrt\n# from sklearn.impute import SimpleImputer\nimport torch\ndevice = torch.device(\"cuda\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1746e0190fd3128cb6a09c7505bd7c196a41e9de"
      },
      "cell_type": "code",
      "source": "class LSTM(torch.nn.Module):\n    def __init__(self, classification=False, class_number=1):\n        super().__init__()\n        input_size = 7\n\n        self.BN_before = torch.nn.BatchNorm1d(10)\n        self.rnn=torch.nn.LSTM(\n            input_size= input_size,\n            hidden_size=128,\n            num_layers=2,\n            batch_first=True\n        )\n        self.linear1 = torch.nn.Linear(128, 1)\n        self.relu = torch.nn.ReLU()\n        self.linear2 = torch.nn.Linear(128, class_number)\n\n    def forward(self,x):\n        out = x\n#         out = self.BN_before(out)\n        output,(h_n,c_n) = self.rnn(out)\n        out = output[:,-1,:] \n        out = self.linear1(out)\n#         out = self.relu(out)\n#         out = self.linear2(out)\n        \n        return out\n    \n    def getFeature(self, x):\n        x = torch.from_numpy(x).to(device)\n        output,(h_n,c_n) = net.rnn(x)\n        out = output[:,-1,:].squeeze(0).cpu().detach().numpy()\n        return out\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac1395d33c5ae573aae92a976f4a836a62ca5169"
      },
      "cell_type": "code",
      "source": "#################################################################\nnet = LSTM(False, 1).to(device)\nnet.load_state_dict(torch.load('./lstm_10.pkl')) # correct here\n#[1, 10, 7] -> [128]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf3ac8e82a61703d13135984ef47a92451fdfc5e"
      },
      "cell_type": "code",
      "source": "\ntrain_epoch = 50\nbatch_size = 32\nlearning_rate = 0.0001\noutput_normalized = True\noutput_delta = True\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db1ec2f29b40327c6b0a50531ac12005c639efba"
      },
      "cell_type": "code",
      "source": "train_dataframe = read_csv('../input/cs410ei339-fall18-stock-price-prediction/train_data.csv', engine='python')\n\ntrain_dataframe = train_dataframe.drop(columns=['Unnamed: 0', 'Time'])\ntrain_dataset = train_dataframe.values\n\nX, delta_Y, original_Y = [],[], []\nfor i in range(len(train_dataset)-30):\n    if (i+1) % 100000 == 0:\n        print(\"{}/{}\".format(i, len(train_dataset)-30))\n    tmp = train_dataset[i:i+30]\n    if tmp[0,0] != tmp[-1,0]:\n        continue\n    tmp = tmp[:, 1:].astype(np.float32)\n    delta_ave_midPrice = np.average(tmp[10:, 0]) - tmp[9, 0]\n    X.append(tmp[:10])\n    delta_Y.append(delta_ave_midPrice)\n    original_Y.append(np.average(tmp[10:, 0]))\nX, delta_Y, original_Y = np.array(X), np.array(delta_Y), np.array(original_Y)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24ca18ca51f6268a7847e4d2232c6a830199d992"
      },
      "cell_type": "code",
      "source": "X[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "004bac4747c6da1ec9cea8d6ac2ef3b95ff0a674"
      },
      "cell_type": "code",
      "source": "if not output_delta:\n    Y = original_Y\nelse:\n    Y = delta_Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bef8dbda17abe6300e92baa41458be36afb936b2"
      },
      "cell_type": "code",
      "source": "def feature_engin(X):\n    XX = X.reshape((-1,70),order=\"F\")\n\n    #the features:\n    # [0:10]: mid price\n    # [10:20]: Last price\n    # [20:30]:Volume\n    # [30:40]:BidPrice1\n    # [40:50]:BidVolume\n    # [50:60]:AskPrice\n    # [60:70]:AskVolume\n    # [70:80]: first order difference of midprice, the first one is constant 0\n    # [80:90]: first order average of midprice, the first one is same as the first element\n    # [90:100]: second order average: the average of the first average\n    # [100:110]: third order average and their difference: (with first five arbitrary)\n    # [110:120]: difference of second order average(with three arbitrary)\n    # [120:130]: the arbrartry average of the difference of the second order average\n    # [130:140]: the difference between BidPrice and Ask Price\n    # [140:150]: the difference between AskVolume and BidVolume\n    # [150:160]: the log sum of the above two things\n    # [160:170]: the average and time difference of the log sum\n    # [170:180]: the average and time difference of the difference between BidPrice and AskPrice\n    # [180:190]: the average and time difference of the difference between AskVolume and BidVolume\n    # [190:200]: arbitrary\n\n    #[70:80]add the first order difference\n    XX = np.append(XX,np.zeros((XX.shape[0],1)), axis = 1)\n    for i in range(9):\n        XX = np.append(XX,XX[:,i+1].reshape(-1,1) - XX[:,i].reshape(-1,1),axis = 1)\n\n    #[80:90] first order average\n    XX = np.append(XX,XX[:,10].reshape(-1,1), axis = 1) #arbitarly choose\n    for i in range(9):\n        XX = np.append(XX,(XX[:,i+1].reshape(-1,1) + XX[:,i].reshape(-1,1))/2,axis = 1)\n\n    #[90:100] second order average\n        #three arbitrary combination of the features\n    XX = np.append(XX,-0.5*XX[:,9].reshape(-1,1),axis = 1)\n    XX = np.append(XX,XX[:,20].reshape(-1,1) - XX[:,10].reshape(-1,1),axis = 1)\n    for i in range(8):\n        XX = np.append(XX,(XX[:,i+82].reshape(-1,1) + XX[:,i+80].reshape(-1,1))/2,axis = 1)\n\n    #[100:110] 5 arbitary + 5 third order average and their difference :\n    XX = np.append(XX,( (XX[:,0] + XX[:,1] + XX[:,2]+XX[:,3]+XX[:,4]).reshape(-1,1))/5,axis = 1)\n    XX = np.append(XX,( (XX[:,5] + XX[:,6] + XX[:,7]+XX[:,8]+XX[:,9]).reshape(-1,1))/5,axis = 1)\n    XX = np.append(XX, (XX[:,101] / XX[:,100] - 1).reshape(-1,1),axis = 1)\n    XX = np.append(XX,( (XX[:,10] + XX[:,11] + XX[:,12]+XX[:,13]+XX[:,14]).reshape(-1,1))/5,axis = 1)\n    XX = np.append(XX,( (XX[:,15] + XX[:,16] + XX[:,17]+XX[:,18]+XX[:,19]).reshape(-1,1))/5,axis = 1)\n    for i in range(3):\n        XX = np.append(XX,(XX[:,i+93].reshape(-1,1) + XX[:,i+97].reshape(-1,1))/2,axis = 1)\n    for i in range(2):\n        XX = np.append(XX,(XX[:,i+106].reshape(-1,1) - XX[:,i+105].reshape(-1,1)),axis = 1)\n\n    #[110:120]: difference of second order average\n    XX = XX = np.append(XX,(XX[:,104] - XX[:,101]).reshape(-1,1),axis = 1)\n    for i in range(7):\n        XX = np.append(XX,((XX[:,i+93]- XX[:,i+90]).reshape(-1,1)),axis = 1)\n    XX = np.append(XX,( (XX[:,110] + XX[:,111] + XX[:,112]+XX[:,113]+XX[:,114]).reshape(-1,1))/5,axis = 1)\n    XX = np.append(XX,( (XX[:,115] + XX[:,116] + XX[:,117]+XX[:,118]).reshape(-1,1))/4,axis = 1)\n    # [120:130]: the arbitrary average of the difference of the second order average\n    for i in range(10):\n        XX = np.append(XX,((XX[:,2*i+100]+ XX[:,i+119]).reshape(-1,1))/2,axis = 1)\n\n    # [130:140]: the difference between BidPrice and AskPrice\n    for i in range(10):\n        XX = np.append(XX,((XX[:,i+50]- XX[:,i+30]).reshape(-1,1)),axis = 1)\n    # [140:150]: the difference between AskVolume and BidVolume\n    for i in range(10):\n        XX = np.append(XX,((XX[:,i+60]- XX[:,i+40]).reshape(-1,1)),axis = 1)\n    # [150:160]: the log sum of the above two things\n    for i in range(10):\n        XX = np.append(XX,( (XX[:,i+140]+ np.log(XX[:,i+130]+0.001)).reshape(-1,1)),axis = 1)\n\n    # [160:170]: the average and time difference of the log sum\n    for i in range(5):\n        XX = np.append(XX,((XX[:,2*i+150]+ XX[:,2*i+151]).reshape(-1,1))/2,axis = 1)\n    for i in range(3):\n        XX = np.append(XX,((XX[:,i+162]- XX[:,i+160]).reshape(-1,1)),axis = 1)\n    XX = np.append(XX,(((XX[:,155]+ XX[:,156]+ XX[:,157]+ XX[:,158]+ XX[:,159])/5).reshape(-1,1)),axis = 1)\n    XX = np.append(XX,((XX[:,168]- (XX[:,150]+ XX[:,151]+ XX[:,152]+ XX[:,153]+ XX[:,154])/5 ).reshape(-1,1)),axis = 1)\n\n    # [170:180]: the average and time difference of the difference between BidPrice and AskPrice\n    for i in range(5):\n        XX = np.append(XX,((XX[:,2*i+130]+ XX[:,2*i+131]).reshape(-1,1))/2,axis = 1)\n    for i in range(3):\n        XX = np.append(XX,((XX[:,i+172]- XX[:,i+170]).reshape(-1,1)),axis = 1)\n    XX = np.append(XX,(((XX[:,135]+ XX[:,136]+ XX[:,137]+ XX[:,138]+ XX[:,139])/5).reshape(-1,1)),axis = 1)\n    XX = np.append(XX,((XX[:,178]- (XX[:,130]+ XX[:,131]+ XX[:,132]+ XX[:,133]+ XX[:,134])/5 ).reshape(-1,1)),axis = 1)\n\n    # [180:190]:  the average and time difference of the difference between AskVolume and BidVolume \n    for i in range(5):\n        XX = np.append(XX,((XX[:,2*i+140]+ XX[:,2*i+141]).reshape(-1,1))/2,axis = 1)\n    for i in range(3):\n        XX = np.append(XX,((XX[:,i+182]- XX[:,i+180]).reshape(-1,1)),axis = 1)\n    XX = np.append(XX,(((XX[:,145]+ XX[:,146]+ XX[:,147]+ XX[:,148]+ XX[:,149])/5).reshape(-1,1)),axis = 1)\n    XX = np.append(XX,((XX[:,188]- (XX[:,140]+ XX[:,141]+ XX[:,142]+ XX[:,143]+ XX[:,144])/5 ).reshape(-1,1)),axis = 1)\n\n    # [190:200]: arbitrary\n\n#     num_iter = math.floor(X.shape[0]/128)\n#     s = []\n#     print(X.shape)\n#     for i in range(num_iter):\n#         s.append(net.getFeature(X[i*128:(i+1)*128]))\n#     s = np.array(s).reshape(-1, 128)\n#     s2 = net.getFeature(X[num_iter*128:])\n#     s_final  = np.vstack((s, s2))\n\n#     XX_final = np.hstack((XX, s_final))\n#     XX = XX_final\n#     print(XX.shape)\n    return XX\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d54602d41d7a5c3a748a6a3d2bc85a00de4a71dc"
      },
      "cell_type": "code",
      "source": "XX = feature_engin(X)\nXX[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c07eede95b9910dcea27daa4173abc6ed5c1e04d"
      },
      "cell_type": "code",
      "source": "import math\nX_mean = np.mean(X, axis=(1, ))[:, np.newaxis, :]\nX_std = np.std(X, axis=(1, ))[:, np.newaxis, :] + 0.01\nX_normalized = (X-X_mean) / X_std\n\nnum_iter = math.floor(X_normalized.shape[0]/128)\ns = []\nfor i in range(num_iter):\n    s.append(net.getFeature(X_normalized[i*128:(i+1)*128]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9e49996639eb71e11de3a359d94d7f353a42fec"
      },
      "cell_type": "code",
      "source": "s = np.array(s).reshape(-1, 128)\ns2 = net.getFeature(X_normalized[num_iter*128:])\ns_final  = np.vstack((s, s2))\n\nXX_final = np.hstack((XX, s_final))\nprint(XX_final.shape)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96b1e412c68cd0ec7739d03a7e5b8745feabd2d0"
      },
      "cell_type": "code",
      "source": "XX = XX_final",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26d23071b16d42252ae4e7f91ab2c0c1a976d4a9"
      },
      "cell_type": "code",
      "source": "XX = X.reshape(-1,70)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9d2828a901d411c115df3f2b491bad4cfd9f443"
      },
      "cell_type": "code",
      "source": "seed = 7\ntest_size = 0.33\ntrain_number = int(0.8 * len(XX))\ntrain_X, train_Y = XX[:], Y[:]\nprint(train_number)\nprint(XX.shape)\nprint(train_X.shape)\nval_X, val_Y =  XX[:], Y[:]\n# train_X = pd.DataFrame(train_X,columns=[\"t\"+str(i) for i in range(190)])\n# # train_Y = pd.DataFrame(train_Y,columns=[i for i in range(190)])\n# val_X = pd.DataFrame(val_X,columns=[\"f\"+str(i) for i in range(190)])\n# print(train_X.columns)\n# print(val_X.columns)\n# val_Y = pd.DataFrame(val_Y,columns=[i for i in range(190)])\n# train_X, train_Y = X[:train_number].reshape((-1,70)), Y[:train_number]\n# val_X, val_Y =  X[train_number:].reshape((-1,70)), original_Y[train_number:]\n# val_X = val_X[:, :70]\n# train_X = train_X[:, :70]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "172cb026064946a9bb7a8ad5447b979783a3a3e4"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6755c6c891ec7ca4d96239dc36f05012edcb70aa",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# my_pipeline = Pipeline([('imputer', Imputer()), ('xgbrg', XGBRegressor())])\n# param_grid = {\n#     \"xgbrg__n_estimators\": [200],\n#     \"xgbrg__learning_rate\": [0.01],\n#     \"xgbrg__max_depth\" :[3],#3\n#     \"xgbrg__min_child_weight\" :[6],#6\n#     \"xgbrg__gamma\" :[0], #0\n#     \"xgbrg__subsample\" :[0.7],\n#     \"xgbrg__colsample_bytree\" :[0.9],\n#     \"xgbrg__scale_pos_weight\" :[1],\n#     \"xgbrg__reg_alpha\" :[0.01]\n# }\n\n# # train_X_matrix = train_X.as_matrix()\n# # train_Y_matrix = train_Y.as_matrix()\n# # val_X_matrix = val_X.as_matrix()\n# # val_Y_matrix = val_Y.as_matrix()\n\n\n# fit_params = {\"xgbrg__eval_set\": [(val_X, val_Y)], \n#               \"xgbrg__early_stopping_rounds\": 10, \n#               \"xgbrg__verbose\": False} \n# scorer = make_scorer(lambda val, pre: sqrt(mean_squared_error(val, pre)) , greater_is_better= False)\n# searchCV = GridSearchCV(my_pipeline, cv=5, param_grid=param_grid, fit_params=fit_params, n_jobs=-1 , scoring=scorer)\n# searchCV.fit(train_X, train_Y)  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e92053f4cef7257b6f951745757e252a116b3015"
      },
      "cell_type": "markdown",
      "source": "first search, step 2 max_depth: 3, min child_weight 5, second search max_depth:3 min_child_weight:6\n\ngamma tried 0, 0.05, 0.1 0.2, 0.3 best 0\n\nsubsample  0.7 cosample_bytree 0.9\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d318700da66b21f3e66ba26032ef00587962ee12"
      },
      "cell_type": "code",
      "source": "# print(searchCV.best_params_ )\n# print(searchCV.cv_results_['mean_train_score'])\n# print(searchCV.cv_results_['mean_test_score'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fdd4898a07b54e99605fa3e7f815e53a5c6e23ca"
      },
      "cell_type": "code",
      "source": "model = XGBRegressor(n_estimators=100)\n# model = XGBRegressor()\nmodel.fit(train_X,train_Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02accd49cb408ff5ad4c81cf9a3a4e7c4c2a33be"
      },
      "cell_type": "code",
      "source": "print(train_X.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68fc8e8a3fda18af8999ce13c99305d06270210b"
      },
      "cell_type": "code",
      "source": "y_pred = model.predict(val_X)\nprint(y_pred.shape)\nprint(val_Y.shape)\naccuracy = sqrt( mean_squared_error(val_Y, y_pred))\naccuracy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47088d58021a8536710b429af26bca802abfb384"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc06d5b57173405ba2f54de1f4d60202a00d9e2a"
      },
      "cell_type": "code",
      "source": "# accuracy = sqrt( mean_squared_error(val_Y, y_pred))\n# accuracy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf8e5ca2fa21cc7c907c30bc530a94f57d80a28c"
      },
      "cell_type": "code",
      "source": "net = LSTM(False, 1).to(torch.device(\"cuda\"))\nnet.load_state_dict(torch.load('../input/lstmpara/lstm_10.pkl')) # correct here",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4caeb3c124645df05eebd769fbe62ec90d8f0c63"
      },
      "cell_type": "code",
      "source": "# load the dataset\ntest_dataframe = read_csv('../input/cs410ei339-fall18-stock-price-prediction/test_data.csv', engine='python')\n\ntest_dataframe = test_dataframe.drop(columns=['Date', 'Unnamed: 0', 'Time'])\ntest_dataset = test_dataframe.values\ntest_reshape = test_dataset.reshape(1000, 10, 7).astype(np.float32)#.astype(np.float64)\n\n# \nXX = feature_engin(test_reshape)\nX = test_reshape\n\nX_mean = np.mean(X, axis=(1, ))[:, np.newaxis, :]\nX_std = np.std(X, axis=(1, ))[:, np.newaxis, :] + 0.01\nX_normalized = (X-X_mean) / X_std\n\nnum_iter = math.floor(X_normalized.shape[0]/128)\ns = []\nprint(X.shape)\nfor i in range(num_iter):\n    s.append(net.getFeature(X_normalized[i*128:(i+1)*128]))\ns = np.array(s).reshape(-1, 128)\nprint(s.shape)\ns2 = net.getFeature(X_normalized[num_iter*128:])\ns_final  = np.vstack((s, s2))\n\nXX_final = np.hstack((XX, s_final))\nXX = XX_final\nprint(XX.shape)\ntest = XX\nprint(test.shape)\nresult = model.predict(test)\nfor i, item in enumerate(result):\n    print(\"{},{}\".format(i+1, float(test_reshape[i, 9, 0]) + float(item)))\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "543854415a1a811fec62e01da884480e1c770860"
      },
      "cell_type": "code",
      "source": "  a= 7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}