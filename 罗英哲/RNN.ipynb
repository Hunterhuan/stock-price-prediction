{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "tf.reset_default_graph()\n",
    "\n",
    "rnn_unit=32\n",
    "lstm_layers=2     \n",
    "input_size=40\n",
    "output_size=1\n",
    "lr=0.001        \n",
    "\n",
    "f=open('train_data.csv')\n",
    "df=pd.read_csv(f)    \n",
    "train=df.iloc[:,3:10].values  \n",
    "volume=df.iloc[:,5].values\n",
    "train = np.delete(train,2,axis = 1)\n",
    "train = np.delete(train,2,axis = 1)\n",
    "train = np.delete(train,3,axis = 1)\n",
    "for i in range(len(train)):\n",
    "    train[i][2] = math.log(train[i][2]/train[i][3],10)\n",
    "    if i > 0:\n",
    "        train[i][1] = train[i][1]-train[i-1][1]\n",
    "    else:\n",
    "        train[i][1] = 0\n",
    "    train[i][3] = math.log(volume[i],10)\n",
    "f2=open('test_data.csv')\n",
    "df2=pd.read_csv(f2)\n",
    "test=df2.iloc[:,3:10].values\n",
    "test = np.delete(test,2,axis = 1)\n",
    "test = np.delete(test,2,axis = 1)\n",
    "test = np.delete(test,3,axis = 1)\n",
    "volume_test=df2.iloc[:,5].values\n",
    "for i in range(len(test)):\n",
    "    test[i][2] = math.log(test[i][2]/test[i][3],10)\n",
    "    if i > 0:\n",
    "        test[i][1] = test[i][1]-test[i-1][1]\n",
    "    else:\n",
    "        test[i][1] = 0\n",
    "    test[i][3] = math.log(volume_test[i],10)\n",
    "train_date = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_data(batch_size = 2000, time_step = 1):\n",
    "    batch_index=[]\n",
    "    normalized_train_data=(train-train_mean)/train_std  #标准化\n",
    "    train_x,train_y=[],[]   #训练集\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while(i < len(normalized_train_data)-time_step-30):\n",
    "        if train_date[i] != train_date[i+29]:\n",
    "            i += 29\n",
    "        if j % batch_size == 0:\n",
    "            batch_index.append(j)\n",
    "        x = np.reshape(normalized_train_data[i:i+10,:4],[1,40])\n",
    "        y = np.reshape(np.mean(normalized_train_data[i+10:i+30,0]),[1,1])\n",
    "        now = x[0][36]\n",
    "        goal = y[0][0]\n",
    "        dif = goal - now\n",
    "        dif = np.reshape(dif,[1,1])\n",
    "        train_x.append(x.tolist())\n",
    "        train_y.append(dif.tolist())\n",
    "        i += 1\n",
    "        j += 1\n",
    "    batch_index.append(j-30-time_step-1)\n",
    "    return batch_index,train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data(time_step=1):\n",
    "    normalized_test_data=(test-test_mean)/test_std  #标准化\n",
    "    test_x = []\n",
    "    for i in range(1000):\n",
    "        x=np.reshape(normalized_test_data[i*10:(i+1)*10,:4],[1,40])\n",
    "        test_x.append(x.tolist())\n",
    "    return test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights={\n",
    "         'in':tf.Variable(tf.random_normal([input_size,rnn_unit])),\n",
    "         'out':tf.Variable(tf.random_normal([rnn_unit,1]))\n",
    "        }\n",
    "biases={\n",
    "        'in':tf.Variable(tf.constant(0.1,shape=[rnn_unit,])),\n",
    "        'out':tf.Variable(tf.constant(0.1,shape=[1,]))\n",
    "       }\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstmCell():\n",
    "    #basicLstm单元\n",
    "    basicLstm = tf.nn.rnn_cell.BasicRNNCell(rnn_unit)\n",
    "    # dropout\n",
    "    drop = tf.nn.rnn_cell.DropoutWrapper(basicLstm, output_keep_prob=keep_prob)\n",
    "    return basicLstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mean = np.mean(train,axis = 0)\n",
    "train_std = np.std(train,axis = 0)\n",
    "test_mean = np.mean(test,axis = 0)\n",
    "test_std = np.std(test,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm(X):\n",
    "    \n",
    "    batch_size=tf.shape(X)[0]\n",
    "    time_step=tf.shape(X)[1]\n",
    "    w_in=weights['in']\n",
    "    b_in=biases['in']\n",
    "    input=tf.reshape(X,[-1,input_size])  #需要将tensor转成2维进行计算，计算后的结果作为隐藏层的输入\n",
    "    input_rnn=tf.matmul(input,w_in)+b_in\n",
    "    input_rnn=tf.reshape(input_rnn,[-1,time_step,rnn_unit])  #将tensor转成3维，作为lstm cell的输入\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([lstmCell() for i in range(lstm_layers)])\n",
    "    init_state=cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    output_rnn,final_states=tf.nn.dynamic_rnn(cell, input_rnn,initial_state=init_state, dtype=tf.float32)\n",
    "    output=tf.reshape(output_rnn,[-1,rnn_unit]) \n",
    "    w_out=weights['out']\n",
    "    b_out=biases['out']\n",
    "    pred=tf.matmul(output,w_out)+b_out\n",
    "    return pred,final_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 0  loss: 0.08078449\n",
      "Number of iterations: 1  loss: 0.04096253\n",
      "Number of iterations: 2  loss: 0.024491055\n",
      "Number of iterations: 3  loss: 0.016097795\n",
      "Number of iterations: 4  loss: 0.011393167\n",
      "Number of iterations: 5  loss: 0.008145808\n",
      "Number of iterations: 6  loss: 0.0058888895\n",
      "Number of iterations: 7  loss: 0.0042308285\n",
      "Number of iterations: 8  loss: 0.0032296502\n"
     ]
    }
   ],
   "source": [
    "def train_lstm(batch_size=2000,time_step=1):\n",
    "    X=tf.placeholder(tf.float32, shape=[None,time_step,input_size])\n",
    "    Y=tf.placeholder(tf.float32, shape=[None,time_step,output_size])\n",
    "    batch_index,train_x,train_y=get_train_data(batch_size,time_step)\n",
    "    with tf.variable_scope(\"sec_lstm\"):\n",
    "        pred,_=lstm(X)\n",
    "    loss=tf.reduce_mean(tf.square(tf.reshape(pred,[-1])-tf.reshape(Y, [-1])))\n",
    "    train_op=tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    saver=tf.train.Saver(tf.global_variables(),max_to_keep=15)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(10):     \n",
    "            for step in range(len(batch_index)-2):\n",
    "                _,loss_=sess.run([train_op,loss],feed_dict={X:train_x[batch_index[step]:batch_index[step+1]],Y:train_y[batch_index[step]:batch_index[step+1]],keep_prob:0.5})\n",
    "            print(\"Number of iterations:\",i,\" loss:\",loss_)\n",
    "        print(\"model_save: \",saver.save(sess,'model_save2\\\\modle.ckpt'))\n",
    "        print(\"The train has finished\")\n",
    "train_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prediction(time_step=1):\n",
    "    X=tf.placeholder(tf.float32, shape=[None,time_step,input_size])\n",
    "    test_x=get_test_data(time_step)\n",
    "    with tf.variable_scope(\"sec_lstm\",reuse=tf.AUTO_REUSE):\n",
    "        pred,_=lstm(X)\n",
    "    saver=tf.train.Saver(tf.global_variables())\n",
    "    with tf.Session() as sess:\n",
    "        #参数恢复\n",
    "        module_file = tf.train.latest_checkpoint('model_save2')\n",
    "        saver.restore(sess, module_file)\n",
    "        test_predict=[]\n",
    "        for step in range(len(test_x)):\n",
    "            prob=sess.run(pred,feed_dict={X:[test_x[step]],keep_prob:1})\n",
    "            predict=prob.reshape((-1))\n",
    "            test_predict.extend(predict)\n",
    "        big = test_predict\n",
    "        for i in range(len(test_predict)):\n",
    "            test_predict[i] = ((test_x[i][0][36]+test_predict[i]*0.5)*test_std[0]+test_mean[0])\n",
    "        test_predict = np.array(test_predict)\n",
    "        xx = []\n",
    "        for i in range(len(test_predict)):\n",
    "            xx.append(i)\n",
    "            if abs(test_predict[i] - (test_x[i][0][36]*test_std[0]+test_mean[0])) > 0.002:\n",
    "                test_predict[i] = (test_x[i][0][36]*test_std[0]+test_mean[0])*0.95+test_predict[i]*0.05\n",
    "        plt.figure()\n",
    "        plt.plot(xx, test_predict, color='b')\n",
    "        plt.show()\n",
    "    return test_predict,big\n",
    "\n",
    "ans,big= prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
